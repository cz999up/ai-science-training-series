(venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ # If MODEL_DIR already exisits from previous runs, delete it.                                                        (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ export MODEL_DIR=model_dir_bert_large_pytorch                                                                        (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ if [ -d "$MODEL_DIR" ]; then rm -Rf $MODEL_DIR; fi                                                                   python run.py CSX --job_labels name=bert_pt \                                                                                                                                                  --params configs/bert_large_MSL128_sampleds512.yaml \                                                                                                                                          --num_workers_per_csx=1 --mode train \                                                                                                                                                         --model_dir $MODEL_DIR --mount_dirs /home/ /software/ \                                                                                                                                        --python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \                                                                                                                                             --compile_dir $(whoami) |& tee mytest.logrm: cannot remove 'model_dir_bert_large_pytorch/cerebras_logs/train/20240325_171650': Directory not empty                                             (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$                                                                                                                      (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ python run.py CSX --job_labels name=bert_pt \                                                                        > --params configs/bert_large_MSL128_sampleds512.yaml \                                                                                                                                        > --num_workers_per_csx=1 --mode train \                                                                                                                                                       > --model_dir $MODEL_DIR --mount_dirs /home/ /software/ \                                                                                                                                      > --python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \                                                                                                                                           > --compile_dir $(whoami) |& tee mytest.log                                                                                                                                                    2024-03-25 17:27:03,887 INFO:   Effective batch size is 512.                                                                                                                                   2024-03-25 17:27:03,912 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in "model_dir_bert_large_pytorch" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.
2024-03-25 17:27:03,913 INFO:   No checkpoints were found in "model_dir_bert_large_pytorch".
2024-03-25 17:27:03,913 INFO:   No checkpoint was provided. Using randomly initialized model parameters.
2024-03-25 17:27:05,233 INFO:   Saving checkpoint at step 0
2024-03-25 17:27:32,641 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl
2024-03-25 17:27:47,666 INFO:   Compiling the model. This may take a few minutes.
2024-03-25 17:27:47,667 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-03-25 17:27:48,877 INFO:   Initiating a new image build job against the cluster server.
2024-03-25 17:27:48,982 INFO:   Custom worker image build is disabled from server.
2024-03-25 17:27:48,989 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-03-25 17:27:49,303 INFO:   Initiating a new compile wsjob against the cluster server.
2024-03-25 17:27:49,414 INFO:   compile job id: wsjob-pxpjly5c5insfa4rydga7k, remote log path: /n1/wsjob/workdir/job-operator/wsjob-pxpjly5c5insfa4rydga7k
2024-03-25 17:27:59,455 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.

2024-03-25 17:38:39,781 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 execute job(s) running using 1 system(s), 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.
2024-03-25 17:38:49,792 INFO:   Poll ingress status: Waiting for job service readiness.
2024-03-25 17:39:19,832 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-03-25 17:39:24,360 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_8939750200954608837
2024-03-25 17:39:24,365 INFO:   Heartbeat thread stopped for wsjob-pxpjly5c5insfa4rydga7k.
2024-03-25 17:39:24,368 INFO:   Compile was successful!
2024-03-25 17:39:24,372 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.
2024-03-25 17:39:26,674 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-03-25 17:39:26,998 INFO:   Initiating a new execute wsjob against the cluster server.
2024-03-25 17:39:27,121 INFO:   execute job id: wsjob-eyboqfa5zkfshlsecgnaxh, remote log path: /n1/wsjob/workdir/job-operator/wsjob-eyboqfa5zkfshlsecgnaxh
2024-03-25 17:39:37,162 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 execute job(s) running using 1 system(s), 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.
2024-03-25 17:39:47,170 INFO:   Poll ingress status: Waiting for job running, current job status: Scheduled, msg: job is scheduled.
2024-03-25 17:39:57,190 INFO:   Poll ingress status: Waiting for job service readiness.
2024-03-25 17:40:17,227 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-03-25 17:40:17,440 INFO:   Preparing to execute using 1 CSX
2024-03-25 17:40:47,300 INFO:   About to send initial weights
2024-03-25 17:41:21,431 INFO:   Finished sending initial weights
2024-03-25 17:41:21,434 INFO:   Finalizing appliance staging for the run
2024-03-25 17:41:21,453 INFO:   Waiting for device programming to complete
2024-03-25 17:43:25,318 INFO:   Device programming is complete
2024-03-25 17:43:26,254 INFO:   Using network type: ROCE
2024-03-25 17:43:26,255 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...
2024-03-25 17:43:26,278 INFO:   Input workers have begun streaming input data
2024-03-25 17:43:43,081 INFO:   Appliance staging is complete
2024-03-25 17:43:43,085 INFO:   Beginning appliance run
2024-03-25 17:44:00,303 INFO:   | Train Device=CSX, Step=100, Loss=9.39062, Rate=2985.89 samples/sec, GlobalRate=2985.90 samples/sec
^[2024-03-25 17:44:17,931 INFO:   | Train Device=CSX, Step=200, Loss=8.70312, Rate=2937.04 samples/sec, GlobalRate=2944.62 samples/sec
2024-03-25 17:44:35,487 INFO:   | Train Device=CSX, Step=300, Loss=7.79688, Rate=2924.65 samples/sec, GlobalRate=2935.15 samples/sec
2024-03-25 17:44:52,992 INFO:   | Train Device=CSX, Step=400, Loss=7.39062, Rate=2924.74 samples/sec, GlobalRate=2932.56 samples/sec
2024-03-25 17:45:10,702 INFO:   | Train Device=CSX, Step=500, Loss=7.80469, Rate=2904.60 samples/sec, GlobalRate=2924.19 samples/sec
2024-03-25 17:45:28,141 INFO:   | Train Device=CSX, Step=600, Loss=7.53125, Rate=2923.33 samples/sec, GlobalRate=2926.12 samples/sec
2024-03-25 17:45:45,753 INFO:   | Train Device=CSX, Step=700, Loss=7.35156, Rate=2913.67 samples/sec, GlobalRate=2923.41 samples/sec
2024-03-25 17:46:03,292 INFO:   | Train Device=CSX, Step=800, Loss=7.27344, Rate=2916.94 samples/sec, GlobalRate=2922.87 samples/sec
2024-03-25 17:46:20,801 INFO:   | Train Device=CSX, Step=900, Loss=7.35938, Rate=2921.37 samples/sec, GlobalRate=2923.03 samples/sec
2024-03-25 17:46:38,570 INFO:   | Train Device=CSX, Step=1000, Loss=7.12500, Rate=2897.34 samples/sec, GlobalRate=2918.81 samples/sec
2024-03-25 17:46:38,571 INFO:   Saving checkpoint at step 1000
2024-03-25 17:47:13,433 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_1000.mdl
2024-03-25 17:47:50,736 INFO:   Heartbeat thread stopped for wsjob-eyboqfa5zkfshlsecgnaxh.
2024-03-25 17:47:50,749 INFO:   Training completed successfully!
2024-03-25 17:47:50,750 INFO:   Processed 512000 sample(s) in 175.414242153 seconds.