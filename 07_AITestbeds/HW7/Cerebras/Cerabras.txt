(venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ # If MODEL_DIR already exisits from previous runs, delete it.                                                        (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ export MODEL_DIR=model_dir_bert_large_pytorch                                                                        (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ if [ -d "$MODEL_DIR" ]; then rm -Rf $MODEL_DIR; fi                                                                   python run.py CSX --job_labels name=bert_pt \                                                                                                                                                  --params configs/bert_large_MSL128_sampleds.yaml \                                                                                                                                             --num_workers_per_csx=1 --mode train \                                                                                                                                                         --model_dir $MODEL_DIR --mount_dirs /home/ /software/ \                                                                                                                                        --python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \                                                                                                                                             --compile_dir $(whoami) |& tee mytest.logrm: cannot remove 'model_dir_bert_large_pytorch/cerebras_logs/train/20240325_172703': Directory not empty                                             (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$                                                                                                                      (venv_cerebras_pt) (base) (venv_cerebras_pt) [chengze@cer-login-02 bert]$ python run.py CSX --job_labels name=bert_pt \                                                                        > --params configs/bert_large_MSL128_sampleds.yaml \                                                                                                                                           > --num_workers_per_csx=1 --mode train \                                                                                                                                                       > --model_dir $MODEL_DIR --mount_dirs /home/ /software/ \                                                                                                                                      > --python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \                                                                                                                                           > --compile_dir $(whoami) |& tee mytest.log                                                                                                                                                    2024-03-25 17:45:17,209 INFO:   Effective batch size is 1024.                                                                                                                                  2024-03-25 17:45:17,234 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in "model_dir_bert_large_pytorch" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.                                                                                                                                                                      2024-03-25 17:45:17,235 INFO:   No checkpoints were found in "model_dir_bert_large_pytorch".                                                                                                   2024-03-25 17:45:17,235 INFO:   No checkpoint was provided. Using randomly initialized model parameters.                                                                                       2024-03-25 17:45:18,489 INFO:   Saving checkpoint at step 0                                                                                                                                    2024-03-25 17:45:47,217 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl                                                                                                 2024-03-25 17:46:01,684 INFO:   Compiling the model. This may take a few minutes.                                                                                                              2024-03-25 17:46:01,686 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.                                  2024-03-25 17:46:02,912 INFO:   Initiating a new image build job against the cluster server.                                                                                                   2024-03-25 17:46:03,025 INFO:   Custom worker image build is disabled from server.                                                                                                             2024-03-25 17:46:03,031 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.                                  2024-03-25 17:46:03,363 INFO:   Initiating a new compile wsjob against the cluster server.                                                                                                     2024-03-25 17:46:03,484 INFO:   compile job id: wsjob-ojokhfmbquthyw5wjmjq5g, remote log path: /n1/wsjob/workdir/job-operator/wsjob-ojokhfmbquthyw5wjmjq5g
2024-03-25 17:46:13,531 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blo$ked by running jobs, 2 execute job(s) running using 2 system(s). For more information, please run 'csctl get jobs'.
2024-03-25 17:48:03,566 INFO:   Poll ingress status: Waiting for job service readiness.
2024-03-25 17:48:33,599 INFO:   Poll ingress status: Waiting for job ingress readiness.
2024-03-25 17:48:53,624 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-03-25 17:48:57,614 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_9465229803081323743
2024-03-25 17:48:57,619 INFO:   Heartbeat thread stopped for wsjob-ojokhfmbquthyw5wjmjq5g.
2024-03-25 17:48:57,621 INFO:   Compile was successful!
2024-03-25 17:48:57,626 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.
2024-03-25 17:48:59,849 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-03-25 17:49:00,204 INFO:   Initiating a new execute wsjob against the cluster server.
2024-03-25 17:49:00,345 INFO:   execute job id: wsjob-ypypay95tftqjcxfyy4xd6, remote log path: /n1/wsjob/workdir/job-operator/wsjob-ypypay95tftqjcxfyy4xd6
2024-03-25 17:49:10,391 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 execute job(s) running using 1 system(s), 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.
2024-03-25 17:49:20,379 INFO:   Poll ingress status: Waiting for job running, current job status: Scheduled, msg: job is scheduled.
2024-03-25 17:49:30,395 INFO:   Poll ingress status: Waiting for job service readiness.
2024-03-25 17:49:50,430 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-03-25 17:49:50,617 INFO:   Preparing to execute using 1 CSX
2024-03-25 17:50:18,793 INFO:   About to send initial weights
2024-03-25 17:50:52,643 INFO:   Finished sending initial weights
2024-03-25 17:50:52,645 INFO:   Finalizing appliance staging for the run
2024-03-25 17:50:52,681 INFO:   Waiting for device programming to complete
2024-03-25 17:52:43,276 INFO:   Device programming is complete
2024-03-25 17:52:44,160 INFO:   Using network type: ROCE
2024-03-25 17:52:44,161 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...
2024-03-25 17:52:44,200 INFO:   Input workers have begun streaming input data
2024-03-25 17:53:08,769 INFO:   Appliance staging is complete
2024-03-25 17:53:08,773 INFO:   Beginning appliance run
2024-03-25 17:53:29,507 INFO:   | Train Device=CSX, Step=100, Loss=9.48438, Rate=4959.03 samples/sec, GlobalRate=4959.03 samples/sec
2024-03-25 17:53:50,569 INFO:   | Train Device=CSX, Step=200, Loss=8.35938, Rate=4900.73 samples/sec, GlobalRate=4909.97 samples/sec
2024-03-25 17:54:11,727 INFO:   | Train Device=CSX, Step=300, Loss=7.91406, Rate=4864.20 samples/sec, GlobalRate=4886.37 samples/sec
2024-03-25 17:54:32,966 INFO:   | Train Device=CSX, Step=400, Loss=7.54688, Rate=4838.41 samples/sec, GlobalRate=4869.92 samples/sec
2024-03-25 17:54:54,222 INFO:   | Train Device=CSX, Step=500, Loss=7.46875, Rate=4825.85 samples/sec, GlobalRate=4859.34 samples/sec
2024-03-25 17:55:15,093 INFO:   | Train Device=CSX, Step=600, Loss=7.39844, Rate=4874.15 samples/sec, GlobalRate=4867.11 samples/sec
2024-03-25 17:55:36,397 INFO:   | Train Device=CSX, Step=700, Loss=7.35156, Rate=4833.64 samples/sec, GlobalRate=4858.38 samples/sec
2024-03-25 17:55:57,472 INFO:   | Train Device=CSX, Step=800, Loss=7.25000, Rate=4848.81 samples/sec, GlobalRate=4858.45 samples/sec
2024-03-25 17:56:18,686 INFO:   | Train Device=CSX, Step=900, Loss=7.21094, Rate=4835.69 samples/sec, GlobalRate=4854.93 samples/sec
2024-03-25 17:56:39,815 INFO:   | Train Device=CSX, Step=1000, Loss=7.07812, Rate=4842.16 samples/sec, GlobalRate=4854.08 samples/sec
2024-03-25 17:56:39,815 INFO:   Saving checkpoint at step 1000
2024-03-25 17:57:15,289 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_1000_20240325_175639.mdl
2024-03-25 17:58:22,888 INFO:   Heartbeat thread stopped for wsjob-ypypay95tftqjcxfyy4xd6.
2024-03-25 17:58:22,904 INFO:   Training completed successfully!
2024-03-25 17:58:22,904 INFO:   Processed 1024000 sample(s) in 210.956617736 seconds.